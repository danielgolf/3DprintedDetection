{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mbpcPlyDPV2y"
   },
   "outputs": [],
   "source": [
    "# not recommended, since it's slow\n",
    "!pip install --upgrade tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A_WOfc9Xhx9k"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WcctKEyftwpG"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jVBQ0siXu0d-"
   },
   "outputs": [],
   "source": [
    "!cp drive/My\\ Drive/3DprintedDetection/rendered_transp_512_16_8_1.tar.gz ./\n",
    "!sha256sum rendered_transp_512_16_8_1.tar.gz\n",
    "!tar xf rendered_transp_512_16_8_1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I-2o_m5aqnuA"
   },
   "outputs": [],
   "source": [
    "!rm -rf images_croped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_mHXc-ddlo36"
   },
   "outputs": [],
   "source": [
    "# train_images/crop_img.py\n",
    "# -------------------------------\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def process(in_path: str, out_path: str, colors=None):\n",
    "    img = cv2.imread(in_path, cv2.IMREAD_UNCHANGED)\n",
    "    assert img.shape == (512, 512, 4)\n",
    "\n",
    "    img, mask = crop_img(img)\n",
    "    save_imgs(img, mask, out_path, colors)\n",
    "\n",
    "\n",
    "def crop_img(img, blowout=True):\n",
    "    mask = np.zeros((512,) * 2, dtype='uint8')\n",
    "    mask[np.where(img[:, :, 3] != 0)] = 255\n",
    "\n",
    "    if blowout:\n",
    "        t_img = cv2.dilate(mask.copy(), np.ones((4, 4), np.uint8), iterations=1)\n",
    "\n",
    "    _, contours, _ = cv2.findContours(t_img.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find object with the biggest bounding box\n",
    "    mx = (0, 0, 0, 0)      # biggest bounding box so far\n",
    "    mx_area = 0\n",
    "    org_area = img.shape[0] * img.shape[1]  # area if original image\n",
    "\n",
    "    for i, cont in enumerate(contours):\n",
    "        x, y, w, h = cv2.boundingRect(cont)\n",
    "        area = w * h\n",
    "        if area > mx_area and area < org_area:\n",
    "            mx = x, y, w, h\n",
    "            mx_area = area\n",
    "\n",
    "    # make bounding box quadratic\n",
    "    x, y, w, h = mx\n",
    "    if w < h:\n",
    "        x -= (h - w) // 2\n",
    "        w = h\n",
    "    elif h < w:\n",
    "        y -= (w - h) // 2\n",
    "        h = w\n",
    "\n",
    "    assert x > 0\n",
    "    assert y > 0\n",
    "    assert x + w < img.shape[1]\n",
    "    assert y + h < img.shape[0]\n",
    "\n",
    "    return img[y:y + h, x:x + w], mask[y:y + h, x:x + w]\n",
    "\n",
    "\n",
    "def resize_img(img, shape=(256, 256), debug=False):\n",
    "    # resize image\n",
    "    if debug and (img.shape[0] < shape[0] or img.shape[1] < shape[1]):\n",
    "        print(\"Image shape is small: \", img.shape)\n",
    "    return cv2.resize(img, shape)\n",
    "\n",
    "\n",
    "def save_imgs(img, mask, out_path: str, colors=None):\n",
    "    if not colors:\n",
    "        img = resize_img(img[:, :, :3], shape=(128, 128))\n",
    "        cv2.imwrite(out_path, img)\n",
    "        return\n",
    "\n",
    "    img = img[:, :, :3]\n",
    "    img = (img * np.random.uniform(low=0.85, high=1.0)).astype('uint8')\n",
    "    yellow_off = np.random.randint(0, 17)\n",
    "    id0, id1 = np.where(img[:, :, 0] > yellow_off)\n",
    "    img[id0, id1, 0] -= yellow_off\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "    mask = np.dstack((mask, mask, mask))\n",
    "    mask_inverse = np.ones(mask.shape, dtype='uint8') * 255 - mask\n",
    "\n",
    "    for j, col in enumerate(colors):\n",
    "        backg = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        backg[:, :] = col\n",
    "        max_diffuse = np.random.randint(10, 41, dtype='uint8')\n",
    "        backg += np.random.randint(0, max_diffuse,\n",
    "                                   size=backg.shape,\n",
    "                                   dtype='uint8')\n",
    "\n",
    "        img_col = cv2.bitwise_and(img, mask)\n",
    "        img_col += cv2.bitwise_and(backg, mask_inverse)\n",
    "        img_col = resize_img(img_col, shape=(128, 128))\n",
    "\n",
    "        out_p = \"{}_col{}{}\".format(out_path[:-4], j, out_path[-4:])\n",
    "        cv2.imwrite(out_p, img_col)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    color_list = [[230, 10, 10], [10, 230, 10], [10, 10, 230], [150, 150, 150]]\n",
    "    color_list += [[0, 0, 0], [200, 200, 10], [10, 200, 200], [200, 10, 200]]\n",
    "\n",
    "    save_path = './images_croped'\n",
    "    if not os.path.isdir(save_path):\n",
    "        os.mkdir(save_path)\n",
    "\n",
    "    path = './images'\n",
    "    subfolders = os.listdir(path)\n",
    "    failed_objects = []\n",
    "    for i, folder in enumerate(subfolders):\n",
    "        msg = 'Fortschritt - Ordner: {} von {}\\r'.format(i, len(subfolders))\n",
    "        print(msg)\n",
    "\n",
    "        if not os.path.isdir('{}/{}'.format(path, folder)):\n",
    "            continue\n",
    "\n",
    "        if not os.path.isdir('%s/%s' % (save_path, folder)):\n",
    "            os.mkdir('%s/%s' % (save_path, folder))\n",
    "\n",
    "        content = os.listdir('{}/{}'.format(path, folder))\n",
    "        for img_name in content:\n",
    "            input_path = '%s/%s/%s' % (path, folder, img_name)\n",
    "            output_path = '%s/%s/%s' % (save_path, folder, img_name)\n",
    "            try:\n",
    "                process(input_path, output_path, color_list)\n",
    "            except AssertionError:\n",
    "                if folder not in failed_objects:\n",
    "                    failed_objects.append(folder)\n",
    "    print('\\n', failed_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "blRBQdNnOtm9"
   },
   "outputs": [],
   "source": [
    "# prediction/calculate_mean_std_batchwise.py\n",
    "# -------------------------------\n",
    "\n",
    "import os\n",
    "\n",
    "cnt = 0\n",
    "PATH = './images_croped/'\n",
    "\n",
    "subfolders = os.listdir(PATH)\n",
    "subfolders = [k for k in subfolders if os.path.isdir('{}{}'.format(PATH, k))]\n",
    "\n",
    "for folder in subfolders:\n",
    "  nb = len([k for k in os.listdir('{}{}'.format(PATH, folder))])\n",
    "  cnt += nb\n",
    "\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hdZslGpW3xzU"
   },
   "outputs": [],
   "source": [
    "# prediction/calculate_mean_std_batchwise.py\n",
    "# -------------------------------\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "TRAIN_PATH = './images_croped/'\n",
    "IMG_WIDTH = 128\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "gen = datagen.flow_from_directory(\n",
    "    directory=TRAIN_PATH,\n",
    "    target_size=(IMG_WIDTH, IMG_WIDTH),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "batches = 88\n",
    "assert float(batches) == cnt / BATCH_SIZE\n",
    "\n",
    "print(\"Calculate mean\")\n",
    "\n",
    "mean = np.zeros((IMG_WIDTH, IMG_WIDTH, 3))\n",
    "for i in range(batches):\n",
    "    X, _ = gen.next()\n",
    "    mean += np.mean(X, axis=0)\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "mean /= batches\n",
    "print(mean.shape)\n",
    "\n",
    "print(\"Calculate std \")\n",
    "\n",
    "var = np.zeros((IMG_WIDTH, IMG_WIDTH, 3))\n",
    "for i in range(batches):\n",
    "    X, _ = gen.next()\n",
    "    var += np.sum((X - mean) ** 2, axis=0)\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "var /= (cnt - 1)\n",
    "std = np.sqrt(var)\n",
    "print(std.shape)\n",
    "\n",
    "np.save('featurewise_mean', mean)\n",
    "np.save('featurewise_std', std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a1MGxS9gtlV8"
   },
   "outputs": [],
   "source": [
    "# prediction/calculate_mean_std_batchwise.py\n",
    "# -------------------------------\n",
    "\n",
    "!cp featurewise_std.npy drive/My\\ Drive/3DprintedDetection/cnn_classification\n",
    "!cp featurewise_mean.npy drive/My\\ Drive/3DprintedDetection/cnn_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dcvBgpDx8LMw"
   },
   "outputs": [],
   "source": [
    "# copy std and mean from Gdrive\n",
    "!cp drive/My\\ Drive/3DprintedDetection/cnn_classification/featurewise_std.npy ./\n",
    "!cp drive/My\\ Drive/3DprintedDetection/cnn_classification/featurewise_mean.npy ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hdyYM9aGb9T-"
   },
   "outputs": [],
   "source": [
    "# prediction/cnn_datagenerator.py\n",
    "# -------------------------------\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "\n",
    "class MyImageDataGen(ImageDataGenerator):\n",
    "    \"\"\" My own ImageDataGenerator which inherit from the original\n",
    "    and applies precalculated std and mean\"\"\"\n",
    "\n",
    "    def __init__(self, mean=None, std=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self._mean = mean\n",
    "        self._std = std\n",
    "\n",
    "    def standardize(self, x):\n",
    "        if self._mean is not None and self._std is not None:\n",
    "            assert x.shape[-3:] == self._mean.shape\n",
    "            assert x.shape[-3:] == self._std.shape\n",
    "\n",
    "        if self.preprocessing_function:\n",
    "            x = self.preprocessing_function(x)\n",
    "        if self.rescale:\n",
    "            x *= self.rescale\n",
    "        if self.samplewise_center:\n",
    "            x -= np.mean(x, keepdims=True)\n",
    "        if self.samplewise_std_normalization:\n",
    "            x /= (np.std(x, keepdims=True) + 1e-6)\n",
    "\n",
    "        if self.featurewise_center:\n",
    "            if self._mean is not None:\n",
    "                x -= self._mean\n",
    "            else:\n",
    "                warnings.warn('This MyImageDataGen specifies '\n",
    "                              '`featurewise_center`, but the mean isn\\'t given.')\n",
    "        if self.featurewise_std_normalization:\n",
    "            if self._std is not None:\n",
    "                x /= (self._std + 1e-6)\n",
    "            else:\n",
    "                warnings.warn('This MyImageDataGen specifies '\n",
    "                              '`featurewise_std_normalization`, '\n",
    "                              'but the std isn\\'t given.')\n",
    "        if self.zca_whitening:\n",
    "            warnings.warn('This MyImageDataGen specifies '\n",
    "                          '`zca_whitening`, but isn\\'t implemented.')\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_train_gen(mean_path='./featurewise_mean.npy', std_path='./featurewise_std.npy'):\n",
    "    mean = np.load(mean_path, allow_pickle=True)\n",
    "    std = np.load(std_path, allow_pickle=True)\n",
    "    kwargs = dict(\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=1. / 255,\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        # samplewise_center=True,\n",
    "        # samplewise_std_normalization=True,\n",
    "\n",
    "        # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # rotation_range=10,\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.02,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.02,\n",
    "        # horizontal_flip=True,  # randomly flip images\n",
    "        # vertical_flip=True,  # randomly flip images\n",
    "    )\n",
    "    datagen = MyImageDataGen(mean, std, **kwargs)\n",
    "    return datagen\n",
    "\n",
    "\n",
    "def get_test_gen(mean_path='./featurewise_mean.npy', std_path='./featurewise_std.npy'):\n",
    "    mean = np.load(mean_path, allow_pickle=True)\n",
    "    std = np.load(std_path, allow_pickle=True)\n",
    "    kwargs = dict(\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=1. / 255,\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        # samplewise_center=True,\n",
    "        # samplewise_std_normalization=True,\n",
    "    )\n",
    "    datagen = MyImageDataGen(mean, std, **kwargs)\n",
    "    return datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JRMsJnA-gnwI"
   },
   "outputs": [],
   "source": [
    "# Tensorflow 2 needed\n",
    "!rm -rf logs\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zj-lTmtYjgjT"
   },
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lY5048OOCZwB"
   },
   "outputs": [],
   "source": [
    "# prediction/cnn_pretrained.py\n",
    "# -------------------------------\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "# from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "### --- paths --- ###\n",
    "\n",
    "TRAIN_PATH = './images_croped'\n",
    "MODEL_JSON = './cnn_vgg16.json'\n",
    "MODEL_WEIGHTS = './cnn_vgg16.hdf5'\n",
    "# LOG_DIR = \"logs/fit\"\n",
    "\n",
    "### --- paths end --- ###\n",
    "\n",
    "### --- parameters --- ###\n",
    "\n",
    "TRAIN_CONV = True\n",
    "\n",
    "img_width = 128\n",
    "num_classes = 45\n",
    "nb_train_samples = 180224\n",
    "\n",
    "reg = 1e-3\n",
    "\n",
    "epochs = 8\n",
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "\n",
    "### --- parameters end --- ###\n",
    "\n",
    "### --- model --- ###\n",
    "\n",
    "if os.path.isfile(MODEL_JSON) and os.path.isfile(MODEL_WEIGHTS):\n",
    "    print('Load model from file')\n",
    "    with open(MODEL_JSON, 'r') as file:\n",
    "        json_string = file.readline()\n",
    "    model = keras.models.model_from_json(json_string)\n",
    "    model.load_weights(MODEL_WEIGHTS)\n",
    "else:\n",
    "    print('Build new model')\n",
    "    # create the base pre-trained model\n",
    "    base_model = VGG16(include_top=False,\n",
    "                       input_shape=(img_width, img_width, 3))\n",
    "\n",
    "    if TRAIN_CONV:\n",
    "        # get output Block 4\n",
    "        x = base_model.get_layer('block4_conv2').output\n",
    "\n",
    "        # last convolutional layers\n",
    "        x = layers.Conv2D(512, (3, 3),\n",
    "                        activation='relu',\n",
    "                        padding='same',\n",
    "                        name='block4_conv3')(x)\n",
    "        x = layers.MaxPooling2D((2, 2), strides=(2, 2),\n",
    "                                name='block4_pool')(x)\n",
    "    else:\n",
    "        # get output Block 4\n",
    "        x = base_model.get_layer('block4_pool').output\n",
    "\n",
    "    # classification block\n",
    "    x = layers.Flatten(name='flatten')(x)\n",
    "\n",
    "    x = layers.Dense(4096, activation='relu', name='fc1',\n",
    "                    kernel_regularizer=keras.regularizers.l2(reg))(x)\n",
    "    x = layers.Dense(4096, activation='relu', name='fc2',\n",
    "                    kernel_regularizer=keras.regularizers.l2(reg))(x)\n",
    "\n",
    "    predictions = layers.Dense(num_classes, activation='softmax',\n",
    "                               name='predictions')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "if TRAIN_CONV:\n",
    "    assert not model.get_layer(name='block4_conv2').trainable\n",
    "    assert model.get_layer(name='block4_conv3').trainable\n",
    "else:\n",
    "    assert not model.get_layer(name='block4_conv3').trainable\n",
    "    assert model.get_layer(name='fc1').trainable\n",
    "\n",
    "### --- end --- ###\n",
    "\n",
    "### --- training --- ###\n",
    "\n",
    "# initiate adam optimizer\n",
    "opt = keras.optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "datagen = get_train_gen().flow_from_directory(\n",
    "    directory=TRAIN_PATH,\n",
    "    target_size=(img_width, img_width),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# tfboard = TensorBoard(log_dir=LOG_DIR, histogram_freq=1)\n",
    "\n",
    "# Fit the model on the batches generated by datagen\n",
    "history = model.fit_generator(\n",
    "    generator=datagen,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    workers=2,\n",
    "    verbose=1 #,\n",
    "    # callbacks=[tfboard]\n",
    ")\n",
    "\n",
    "### --- end training --- ###\n",
    "\n",
    "### --- save model --- ###\n",
    "\n",
    "model.summary()\n",
    "\n",
    "json_string = model.to_json()\n",
    "with open(MODEL_JSON, 'w') as file:\n",
    "    file.write(json_string + '\\n')\n",
    "model.save_weights(MODEL_WEIGHTS)\n",
    "\n",
    "### --- end save --- ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5J1ZwbfUFWEW"
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.savefig('./cnn_vgg16_train.png')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "761CuKXpqyOR"
   },
   "outputs": [],
   "source": [
    "!cp cnn_vgg16.json drive/My\\ Drive/3DprintedDetection/cnn_classification\n",
    "!cp cnn_vgg16.hdf5 drive/My\\ Drive/3DprintedDetection/cnn_classification\n",
    "!cp cnn_vgg16_train.png drive/My\\ Drive/3DprintedDetection/cnn_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qseK_sT9ycfi"
   },
   "outputs": [],
   "source": [
    "# prediction/cnn_own.py\n",
    "# -------------------------------\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Activation, Conv2D, Dense\n",
    "from tensorflow.keras.layers import Dropout, Flatten, MaxPooling2D\n",
    "\n",
    "### --- paths --- ###\n",
    "\n",
    "TRAIN_PATH = './images_croped'\n",
    "MODEL_JSON = './cnn_own.json'\n",
    "MODEL_WEIGHTS = './cnn_own.hdf5'\n",
    "\n",
    "### --- paths end --- ###\n",
    "\n",
    "### --- parameters --- ###\n",
    "\n",
    "img_width = 128\n",
    "num_classes = 45\n",
    "nb_train_samples = 180224\n",
    "\n",
    "reg = 1e-3\n",
    "\n",
    "epochs = 16\n",
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "\n",
    "### --- parameters end --- ###\n",
    "\n",
    "### --- define model --- ###\n",
    "\n",
    "if os.path.isfile(MODEL_JSON) and os.path.isfile(MODEL_WEIGHTS):\n",
    "    print('Load model from file')\n",
    "    with open(MODEL_JSON, 'r') as file:\n",
    "        json_string = file.readline()\n",
    "    model = keras.models.model_from_json(json_string)\n",
    "    model.load_weights(MODEL_WEIGHTS)\n",
    "else:\n",
    "    print('Build new model')\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # ConvLayer 1 - Input\n",
    "    model.add(Conv2D(\n",
    "        32, 3,\n",
    "        # strides=(2, 2),\n",
    "        padding='same',\n",
    "        input_shape=(img_width, img_width, 3),\n",
    "        kernel_regularizer=keras.regularizers.l2(reg)\n",
    "    ))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # ConvLayer 2\n",
    "    model.add(Conv2D(\n",
    "        32, 3,\n",
    "        padding='same',\n",
    "        kernel_regularizer=keras.regularizers.l2(reg)\n",
    "    ))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # ConvLayer 3\n",
    "    model.add(Conv2D(\n",
    "        64, 3,\n",
    "        padding='same',\n",
    "        kernel_regularizer=keras.regularizers.l2(reg)\n",
    "    ))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # ConvLayer 4\n",
    "    model.add(Conv2D(\n",
    "        64, 3,\n",
    "        padding='same',\n",
    "        kernel_regularizer=keras.regularizers.l2(reg)\n",
    "    ))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # ConvLayer 5\n",
    "    model.add(Conv2D(\n",
    "        128, 3,\n",
    "        padding='same',\n",
    "        kernel_regularizer=keras.regularizers.l2(reg)\n",
    "    ))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # ConvLayer 6\n",
    "    model.add(Conv2D(\n",
    "        128, 3,\n",
    "        padding='same',\n",
    "        kernel_regularizer=keras.regularizers.l2(reg)\n",
    "    ))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Flat\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Fully Conected Layer 7\n",
    "    model.add(Dense(2048, kernel_regularizer=keras.regularizers.l2(reg)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Fully Conected Layer 8\n",
    "\n",
    "    model.add(Dense(2048, kernel_regularizer=keras.regularizers.l2(reg)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Fully Connected Layer 9 - Output\n",
    "    model.add(Dense(num_classes, kernel_regularizer=keras.regularizers.l2(reg)))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "### --- end definition --- ###\n",
    "\n",
    "### --- training --- ###\n",
    "\n",
    "# initiate adam optimizer\n",
    "opt = keras.optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "datagen = get_train_gen().flow_from_directory(\n",
    "    directory=TRAIN_PATH,\n",
    "    target_size=(img_width, img_width),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Fit the model on the batches generated by datagen\n",
    "history = model.fit_generator(\n",
    "    generator=datagen,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    workers=2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "### --- end training --- ###\n",
    "\n",
    "### --- save model --- ###\n",
    "\n",
    "model.summary()\n",
    "\n",
    "json_string = model.to_json()\n",
    "with open(MODEL_JSON, 'w') as file:\n",
    "    file.write(json_string + '\\n')\n",
    "model.save_weights(MODEL_WEIGHTS)\n",
    "\n",
    "### --- end save --- ###\n",
    "\n",
    "### --- show learning --- ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IYSuqgknFcuE"
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.savefig('./cnn_own_train.png')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LzKJkLNxeHJR"
   },
   "outputs": [],
   "source": [
    "!cp cnn_own.json drive/My\\ Drive/3DprintedDetection/cnn_classification\n",
    "!cp cnn_own.hdf5 drive/My\\ Drive/3DprintedDetection/cnn_classification\n",
    "!cp cnn_own_train.png drive/My\\ Drive/3DprintedDetection/cnn_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HgZQ667FRamG"
   },
   "outputs": [],
   "source": [
    "# rgb vs. hsv visualization\n",
    "# taken from https://realpython.com/python-opencv-color-spaces/\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "from matplotlib import colors\n",
    "from google.colab import files\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "\n",
    "uploaded = files.upload()\n",
    "fname = list(uploaded.keys())[0]\n",
    "\n",
    "nemo = cv2.imread(fname, 1)\n",
    "if nemo.shape[0] > 512 or nemo.shape[1] > 512:\n",
    "    nemo = cv2.resize(nemo, (512, 512))\n",
    "\n",
    "nemo = cv2.cvtColor(nemo, cv2.COLOR_BGR2RGB)\n",
    "r, g, b = cv2.split(nemo)\n",
    "fig = plt.figure()\n",
    "axis = fig.add_subplot(1, 1, 1, projection=\"3d\")\n",
    "\n",
    "pixel_colors = nemo.reshape((np.shape(nemo)[0]*np.shape(nemo)[1], 3))\n",
    "norm = colors.Normalize(vmin=-1.,vmax=1.)\n",
    "norm.autoscale(pixel_colors)\n",
    "pixel_colors = norm(pixel_colors).tolist()\n",
    "\n",
    "axis.scatter(r.flatten(), g.flatten(), b.flatten(), facecolors=pixel_colors, marker=\".\")\n",
    "axis.set_xlabel(\"Red\")\n",
    "axis.set_ylabel(\"Green\")\n",
    "axis.set_zlabel(\"Blue\")\n",
    "plt.title('RGB-Farbraum')\n",
    "plt.savefig('rgb_viz.png')\n",
    "plt.show()\n",
    "\n",
    "hsv_nemo = cv2.cvtColor(nemo, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "h, s, v = cv2.split(hsv_nemo)\n",
    "fig = plt.figure()\n",
    "axis = fig.add_subplot(1, 1, 1, projection=\"3d\")\n",
    "\n",
    "axis.scatter(h.flatten(), s.flatten(), v.flatten(), facecolors=pixel_colors, marker=\".\")\n",
    "axis.set_xlabel(\"Hue\")\n",
    "axis.set_ylabel(\"Saturation\")\n",
    "axis.set_zlabel(\"Value\")\n",
    "plt.title('HSV-Farbraum')\n",
    "plt.savefig('hsv_viz.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t_QDlJin1BkS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
