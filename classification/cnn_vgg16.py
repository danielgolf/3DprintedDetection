# use GPU
# import plaidml.keras
# plaidml.keras.install_backend()

import os
import matplotlib.pyplot as plt

import keras
from keras import layers
from keras.models import Model
from keras.applications.vgg16 import VGG16
from cnn_datagenerator import get_train_gen

### --- paths --- ###

BASE_PATH = '/'.join(os.getcwd().split('/')[:-1])
TRAIN_PATH = BASE_PATH + '/train_images/images_croped'
MODEL_JSON = './models/cnn_vgg16.json'
MODEL_WEIGHTS = './models/cnn_vgg16.hdf5'

### --- paths end --- ###

### --- parameters --- ###

img_width = 128
num_classes = 45
nb_train_samples = 180224

reg = 1e-3

epochs = 8
batch_size = 64
learning_rate = 1e-4

### --- parameters end --- ###

### --- model --- ###

if os.path.isfile(MODEL_JSON) and os.path.isfile(MODEL_WEIGHTS):
    print('Load model from file')
    with open(MODEL_JSON, 'r') as file:
        json_string = file.readline()
    model = keras.models.model_from_json(json_string)
    model.load_weights(MODEL_WEIGHTS)
else:
    print('Build new model')
    # create the base pre-trained model
    base_model = VGG16(include_top=False,
                       input_shape=(img_width, img_width, 3))

    # get output Block 4
    x = base_model.get_layer('block4_conv2').output

    # last convolutional layers
    x = layers.Conv2D(512, (3, 3),
                      activation='relu',
                      padding='same',
                      name='block4_conv3')(x)
    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)

    # classification block
    x = layers.Flatten(name='flatten')(x)

    x = layers.Dense(4096, activation='relu', name='fc1',
                     kernel_regularizer=keras.regularizers.l2(reg))(x)
    x = layers.Dense(4096, activation='relu', name='fc2',
                     kernel_regularizer=keras.regularizers.l2(reg))(x)

    predictions = layers.Dense(num_classes, activation='softmax',
                               name='predictions')(x)

    model = Model(inputs=base_model.input, outputs=predictions)

    for layer in base_model.layers:
        layer.trainable = False

assert not model.get_layer(name='block4_conv2').trainable
assert model.get_layer(name='block4_conv3').trainable

### --- end --- ###

### --- training --- ###

# initiate adam optimizer
opt = keras.optimizers.adam(lr=learning_rate)

model.compile(
    optimizer=opt,
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

datagen = get_train_gen().flow_from_directory(
    directory=TRAIN_PATH,
    target_size=(img_width, img_width),
    color_mode="rgb",
    batch_size=batch_size,
    class_mode="categorical",
    shuffle=True
)

# Fit the model on the batches generated by datagen
history = model.fit_generator(
    generator=datagen,
    steps_per_epoch=nb_train_samples // batch_size,
    epochs=epochs,
    workers=4 #,
    #verbose=0
)

### --- end training --- ###

### --- save model --- ###

model.summary()

json_string = model.to_json()
with open(MODEL_JSON, 'w') as file:
    file.write(json_string + '\n')
model.save_weights(MODEL_WEIGHTS)

### --- end save --- ###

### --- show learning --- ###

plt.style.use('ggplot')
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['acc'])
plt.ylabel('accuracy')
plt.xlabel('epoch')

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'])
plt.ylabel('loss')
plt.xlabel('epoch')

plt.savefig('./cnn_vgg16_train.png')
plt.close()

### --- end show --- ###
